{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-b31e8824-2ae9-4203-95c3-5808225e079e\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-b31e8824-2ae9-4203-95c3-5808225e079e\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving train2024.csv to train2024.csv\n"
     ]
    }
   ],
   "source": [
    "#Loading the data :\n",
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-c99f07a7-609f-488b-9ec9-e5db06558d9d\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-c99f07a7-609f-488b-9ec9-e5db06558d9d\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving test2024.csv to test2024.csv\n"
     ]
    }
   ],
   "source": [
    "#Loading the data :\n",
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train2024.csv')\n",
    "test_data =  pd.read_csv('test2024.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Preview:\n",
      "             id  clothing_id  age                    title  \\\n",
      "0  riGPBydm2l8e          767   33                      NaN   \n",
      "1  CTVvQyR3luQK         1077   60  Some major design flaws   \n",
      "2  lIod6hI0Wxvn          847   47         Flattering shirt   \n",
      "3  meKOrcX2BXUk         1080   49  Not for the very petite   \n",
      "4  HKVXQ5htsPmJ         1077   24               Flattering   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            review_text  \\\n",
      "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Absolutely wonderful - silky and sexy and comfortable   \n",
      "1  I had such high hopes for this dress and really wanted it to work for me. i initially ordered the petite small (my usual size) but i found this to be outrageously small. so small in fact that i could not zip it up! i reordered it in petite medium, which was just ok. overall, the top half was comfortable and fit nicely, but the bottom half had a very tight under layer and several somewhat cheap (net) over layers. imo, a major design flaw was the net over layer sewn directly into the zipper - it c   \n",
      "2                                                                                                                                                                                                                                                                                                                      This shirt is very flattering to all due to the adjustable front tie. it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan. love this shirt!!!   \n",
      "3              I love tracy reese dresses, but this one is not for the very petite. i am just under 5 feet tall and usually wear a 0p in this brand. this dress was very pretty out of the package but its a lot of dress. the skirt is long and very full so it overwhelmed my small frame. not a stranger to alterations, shortening and narrowing the skirt would take away from the embellishment of the garment. i love the color and the idea of the style but it just did not work on me. i returned this dress.   \n",
      "4                                                                                                                                                                                                                                                                                                                                                I love this dress. i usually get an xs but it runs a little snug in bust so i ordered up a size. very flattering and feminine with the usual retailer flair for style.   \n",
      "\n",
      "   rating  recommended_ind  positive_feedback_count division_name  \\\n",
      "0       4                1                        0     Initmates   \n",
      "1       3                0                        0       General   \n",
      "2       5                1                        6       General   \n",
      "3       2                0                        4       General   \n",
      "4       5                1                        0       General   \n",
      "\n",
      "  department_name class_name  \n",
      "0        Intimate  Intimates  \n",
      "1         Dresses    Dresses  \n",
      "2            Tops    Blouses  \n",
      "3         Dresses    Dresses  \n",
      "4         Dresses    Dresses  \n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Test Data Preview:\n",
      "             id  clothing_id  age                                 title  \\\n",
      "0  jHteQSkbNSgJ         1080   34                                   NaN   \n",
      "1  lHfLqhVSO5qO         1049   50                      My favorite buy!   \n",
      "2  EDq208w4Zx0k          858   39                  Cagrcoal shimmer fun   \n",
      "3  NfNUrYlwDD1B          858   39  Shimmer, surprisingly goes with lots   \n",
      "4  VMdnNne9fUJ4          767   44                              Runs big   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        review_text  \\\n",
      "0                                                                                                                                                                                                   Love this dress!  it's sooo pretty.  i happened to find it in a store, and i'm glad i did bc i never would have ordered it online bc it's petite.  i bought a petite and am 5'8\".  i love the length on me- hits just a little below the knee.  would definitely be a true midi on someone who is truly petite.   \n",
      "1                                                                                                                                                                                                                                                                                                                                                                                      I love, love, love this jumpsuit. it's fun, flirty, and fabulous! every time i wear it, i get nothing but great compliments!   \n",
      "2  I aded this in my basket at hte last mintue to see what it would look like in person. (store pick up). i went with teh darkler color only because i am so pale :-) hte color is really gorgeous, and turns out it mathced everythiing i was trying on with it prefectly. it is a little baggy on me and hte xs is hte msallet size (bummer, no petite). i decided to jkeep it though, because as i said, it matvehd everything. my ejans, pants, and the 3 skirts i waas trying on (of which i ]kept all ) oops.   \n",
      "3                I ordered this in carbon for store pick up, and had a ton of stuff (as always) to try on and used this top to pair (skirts and pants). everything went with it. the color is really nice charcoal with shimmer, and went well with pencil skirts, flare pants, etc. my only compaint is it is a bit big, sleeves are long and it doesn't go in petite. also a bit loose for me, but no xxs... so i kept it and wil ldecide later since the light color is already sold out in hte smallest size...   \n",
      "4                                                                                                             Bought the black xs to go under the larkspur midi dress because they didn't bother lining the skirt portion (grrrrrrrrrrr).\\r\\r\\nmy stats are 34a-28/29-36 and the xs fit very smoothly around the chest and was flowy around my lower half, so i would say it's running big.\\r\\r\\nthe straps are very pretty and it could easily be nightwear too.\\r\\r\\ni'm 5'6\" and it came to just below my knees.   \n",
      "\n",
      "   recommended_ind  positive_feedback_count   division_name department_name  \\\n",
      "0                1                        4         General         Dresses   \n",
      "1                1                        0  General Petite         Bottoms   \n",
      "2                1                        1  General Petite            Tops   \n",
      "3                1                        4  General Petite            Tops   \n",
      "4                1                        0       Initmates        Intimate   \n",
      "\n",
      "  class_name  \n",
      "0    Dresses  \n",
      "1      Pants  \n",
      "2      Knits  \n",
      "3      Knits  \n",
      "4  Intimates  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Training Data Preview:\")\n",
    "print(train_data.head())\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "print(\"Test Data Preview:\")\n",
    "print(test_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16441 entries, 0 to 16440\n",
      "Data columns (total 11 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   id                       16441 non-null  object\n",
      " 1   clothing_id              16441 non-null  int64 \n",
      " 2   age                      16441 non-null  int64 \n",
      " 3   title                    13801 non-null  object\n",
      " 4   review_text              15849 non-null  object\n",
      " 5   rating                   16441 non-null  int64 \n",
      " 6   recommended_ind          16441 non-null  int64 \n",
      " 7   positive_feedback_count  16441 non-null  int64 \n",
      " 8   division_name            16430 non-null  object\n",
      " 9   department_name          16430 non-null  object\n",
      " 10  class_name               16430 non-null  object\n",
      "dtypes: int64(5), object(6)\n",
      "memory usage: 1.4+ MB\n",
      "None\n",
      "id                            0\n",
      "clothing_id                   0\n",
      "age                           0\n",
      "title                      2640\n",
      "review_text                 592\n",
      "rating                        0\n",
      "recommended_ind               0\n",
      "positive_feedback_count       0\n",
      "division_name                11\n",
      "department_name              11\n",
      "class_name                   11\n",
      "dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Testing Data info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7045 entries, 0 to 7044\n",
      "Data columns (total 10 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   id                       7045 non-null   object\n",
      " 1   clothing_id              7045 non-null   int64 \n",
      " 2   age                      7045 non-null   int64 \n",
      " 3   title                    5875 non-null   object\n",
      " 4   review_text              6792 non-null   object\n",
      " 5   recommended_ind          7045 non-null   int64 \n",
      " 6   positive_feedback_count  7045 non-null   int64 \n",
      " 7   division_name            7042 non-null   object\n",
      " 8   department_name          7042 non-null   object\n",
      " 9   class_name               7042 non-null   object\n",
      "dtypes: int64(4), object(6)\n",
      "memory usage: 550.5+ KB\n",
      "None\n",
      "id                            0\n",
      "clothing_id                   0\n",
      "age                           0\n",
      "title                      1170\n",
      "review_text                 253\n",
      "recommended_ind               0\n",
      "positive_feedback_count       0\n",
      "division_name                 3\n",
      "department_name               3\n",
      "class_name                    3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data info:\")\n",
    "print(train_data.info())\n",
    "print(train_data.isnull().sum())\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "print(\"Testing Data info:\")\n",
    "print(test_data.info())\n",
    "print(test_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5NuprygTB7q"
   },
   "source": [
    "I will make a full report for my univariate analysis for the train data to see the variables distributions and  check for class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sweetviz\n",
      "  Downloading sweetviz-2.3.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3 in /usr/local/lib/python3.10/dist-packages (from sweetviz) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from sweetviz) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.1.3 in /usr/local/lib/python3.10/dist-packages (from sweetviz) (3.8.0)\n",
      "Requirement already satisfied: tqdm>=4.43.0 in /usr/local/lib/python3.10/dist-packages (from sweetviz) (4.67.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from sweetviz) (1.13.1)\n",
      "Requirement already satisfied: jinja2>=2.11.1 in /usr/local/lib/python3.10/dist-packages (from sweetviz) (3.1.4)\n",
      "Requirement already satisfied: importlib-resources>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from sweetviz) (6.4.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.1->sweetviz) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->sweetviz) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->sweetviz) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->sweetviz) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->sweetviz) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->sweetviz) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->sweetviz) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->sweetviz) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->sweetviz) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3->sweetviz) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3->sweetviz) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.1.3->sweetviz) (1.17.0)\n",
      "Downloading sweetviz-2.3.1-py3-none-any.whl (15.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.1/15.1 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sweetviz\n",
      "Successfully installed sweetviz-2.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install sweetviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93d283423ff4c3c8d708cb61f77640c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                             |          | [  0%]   00:00 -> (? left)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report Sweetviz_Report.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n"
     ]
    }
   ],
   "source": [
    "import sweetviz as sv\n",
    "\n",
    "\n",
    "#\n",
    "report = sv.analyze(train_data)\n",
    "\n",
    "report.show_html('Sweetviz_Report.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('Sweetviz_Report.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAdFzYc1U8q4"
   },
   "source": [
    "Some EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class distribution:\n",
      "rating\n",
      "5    9192\n",
      "4    3555\n",
      "3    2022\n",
      "2    1100\n",
      "1     572\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# i will Check the ratings classes distributions :\n",
    "class_distribution = train_data['rating'].value_counts()\n",
    "print(f\"class distribution:\\n{class_distribution}\")\n",
    "\n",
    "## We notice a huge imbalance as 56% ( from the report ) of classes are rating 5 which can cause overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Correlation matrix\n",
    "correlation_matrix = train_data[['recommended_ind', 'positive_feedback_count', 'age', 'rating']].corr(method='spearman')\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation with Target\")\n",
    "plt.show()\n",
    "\n",
    " ## The only variable that is correlated with our target variable is recommended_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data[['recommended_ind', 'positive_feedback_count']].hist(bins=20, figsize=(10, 5))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: division_name\n",
      "division_name\n",
      "General           9623\n",
      "General Petite    5740\n",
      "Initmates         1067\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Feature: department_name\n",
      "department_name\n",
      "Tops        7265\n",
      "Dresses     4421\n",
      "Bottoms     2702\n",
      "Intimate    1234\n",
      "Jackets      715\n",
      "Trend         93\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Feature: class_name\n",
      "class_name\n",
      "Dresses           4421\n",
      "Knits             3388\n",
      "Blouses           2123\n",
      "Sweaters          1010\n",
      "Pants              981\n",
      "Jeans              800\n",
      "Fine gauge         744\n",
      "Skirts             681\n",
      "Lounge             494\n",
      "Jackets            485\n",
      "Swim               252\n",
      "Shorts             238\n",
      "Outerwear          230\n",
      "Sleep              153\n",
      "Legwear            125\n",
      "Layering           106\n",
      "Intimates          103\n",
      "Trend               93\n",
      "Casual bottoms       2\n",
      "Chemises             1\n",
      "Name: count, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for feature in ['division_name', 'department_name', 'class_name']:\n",
    "    print(f\"Feature: {feature}\")\n",
    "    print(train_data[feature].value_counts(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Target Values for division_name:\n",
      " division_name\n",
      "General           4.178427\n",
      "General Petite    4.207143\n",
      "Initmates         4.315839\n",
      "Name: rating, dtype: float64 \n",
      "\n",
      "Mean Target Values for department_name:\n",
      " department_name\n",
      "Bottoms     4.278682\n",
      "Dresses     4.147252\n",
      "Intimate    4.316045\n",
      "Jackets     4.293706\n",
      "Tops        4.172058\n",
      "Trend       3.881720\n",
      "Name: rating, dtype: float64 \n",
      "\n",
      "Mean Target Values for class_name:\n",
      " class_name\n",
      "Blouses           4.171455\n",
      "Casual bottoms    4.500000\n",
      "Chemises          4.000000\n",
      "Dresses           4.147252\n",
      "Fine gauge        4.250000\n",
      "Intimates         4.291262\n",
      "Jackets           4.329897\n",
      "Jeans             4.397500\n",
      "Knits             4.146694\n",
      "Layering          4.377358\n",
      "Legwear           4.416000\n",
      "Lounge            4.352227\n",
      "Outerwear         4.217391\n",
      "Pants             4.229358\n",
      "Shorts            4.235294\n",
      "Skirts            4.224670\n",
      "Sleep             4.320261\n",
      "Sweaters          4.200990\n",
      "Swim              4.178571\n",
      "Trend             3.881720\n",
      "Name: rating, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for feature in ['division_name', 'department_name', 'class_name']:\n",
    "    pivot = train_data.groupby(feature)['rating'].mean()\n",
    "    print(f\"Mean Target Values for {feature}:\\n\", pivot, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Feature       VIF\n",
      "0                    const  6.012975\n",
      "1          recommended_ind  1.005064\n",
      "2  positive_feedback_count  1.005064\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "# Calculate VIF\n",
    "X = train_data[['recommended_ind', 'positive_feedback_count']]\n",
    "X = add_constant(X)\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif[\"Feature\"] = X.columns\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "print(vif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wdRb4P4bxHB3"
   },
   "source": [
    "Here i defined my stopwords . i eliminated them in many approaches before but for my highest public score i didn't . The same for lemmatizing , i didn't do for this appraoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'themselves', 'during', 'why', 'ain', 'as', \"shan't\", 'd', 'ours', 'our', 'wouldn', 'shan', \"couldn't\", 'itself', \"haven't\", 'yourselves', 'nor', 'my', 'were', \"shouldn't\", 'you', 'its', 'they', 'herself', 'between', 'had', \"mustn't\", 'and', \"you've\", \"doesn't\", 'above', 'o', 'then', \"you're\", 'these', 'is', 'at', 'who', 'now', 'if', 'down', 'it', 'this', 'didn', 'up', 'she', 'what', 'shouldn', 'haven', 'being', 'because', 'through', 'isn', 'am', \"won't\", 'her', \"you'll\", 'wasn', 'again', 'that', 'so', 'doesn', 'mightn', 'm', 'himself', 'with', 'them', 'hasn', \"you'd\", \"wasn't\", 'myself', 'same', \"aren't\", 'aren', 'other', 've', 'those', 'should', 'here', 'yourself', 'has', \"didn't\", 'about', 'whom', 'mustn', 'both', 'there', 'yours', \"she's\", 't', 'such', 'all', 'couldn', 'few', 'below', 'will', 'weren', 'in', \"that'll\", 'y', \"weren't\", \"should've\", 'are', 'won', 'into', 'his', 'more', 's', 'before', 'by', 'of', 'than', 'does', 'any', \"don't\", 'where', 'can', 'don', 'until', 're', 'the', \"mightn't\", 'him', 'further', 'under', 'when', 'out', 'did', \"hasn't\", 'theirs', 'be', 'while', 'i', 'against', 'off', 'an', 'needn', 'ourselves', \"hadn't\", \"wouldn't\", 'after', 'll', 'hers', 'doing', 'been', 'for', 'to', \"needn't\", 'each', 'your', 'their', 'do', 'on', 'ma', 'over', 'having', \"it's\", 'once', 'hadn', 'from', 'which', 'have', 'he', 'some', 'was', 'own', 'me', 'how', \"isn't\", 'a', 'we', 'or'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "# Loading English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "# here i defined some of the negations and sentiment modifiers that i thought it will be better to retain them :\n",
    "important_words = {'not', 'no', 'never', 'very', 'quite', 'almost', 'too', 'just', 'only', 'really', 'somewhat', 'rather', 'extremely', 'most','but','however'}\n",
    "\n",
    "\n",
    "stopwordss = stop_words - important_words\n",
    "print(stopwordss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')  # Tokenizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')\n",
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    # Tokenizing the text\n",
    "    words = word_tokenize(text)\n",
    "    # Lemmatizing each word\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    return ' '.join(lemmatized_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPZ3m6u8UCXI"
   },
   "source": [
    "text(the titles and reviews ) cleaning i did for this approach :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                         No title provided Absolutely wonderful - silky and sexy and comfortable\n",
      "1    Some major design flaws I had such high hopes for this dress and really wanted it to work for me. i initially ordered the petite small (my usual size) but i found this to be outrageously small. so small in fact that i could not zip it up! i reordered it in petite medium, which was just ok. overall, the top half was comfortable and fit nicely, but the bottom half had a very tight under layer and several somewhat cheap (net) over layers. imo, a major design flaw was the net over layer sewn directly into the zipper - it c\n",
      "2                                                                                                                                                                                                                                                                                                                               Flattering shirt This shirt is very flattering to all due to the adjustable front tie. it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan. love this shirt!!!\n",
      "3                Not for the very petite I love tracy reese dresses, but this one is not for the very petite. i am just under 5 feet tall and usually wear a 0p in this brand. this dress was very pretty out of the package but its a lot of dress. the skirt is long and very full so it overwhelmed my small frame. not a stranger to alterations, shortening and narrowing the skirt would take away from the embellishment of the garment. i love the color and the idea of the style but it just did not work on me. i returned this dress.\n",
      "4                                                                                                                                                                                                                                                                                                                                                               Flattering I love this dress. i usually get an xs but it runs a little snug in bust so i ordered up a size. very flattering and feminine with the usual retailer flair for style.\n",
      "Name: full_text, dtype: object\n",
      "0                                                                                                                                                                                                          No title provided Love this dress!  it's sooo pretty.  i happened to find it in a store, and i'm glad i did bc i never would have ordered it online bc it's petite.  i bought a petite and am 5'8\".  i love the length on me- hits just a little below the knee.  would definitely be a true midi on someone who is truly petite.\n",
      "1                                                                                                                                                                                                                                                                                                                                                                                              My favorite buy! I love, love, love this jumpsuit. it's fun, flirty, and fabulous! every time i wear it, i get nothing but great compliments!\n",
      "2      Cagrcoal shimmer fun I aded this in my basket at hte last mintue to see what it would look like in person. (store pick up). i went with teh darkler color only because i am so pale :-) hte color is really gorgeous, and turns out it mathced everythiing i was trying on with it prefectly. it is a little baggy on me and hte xs is hte msallet size (bummer, no petite). i decided to jkeep it though, because as i said, it matvehd everything. my ejans, pants, and the 3 skirts i waas trying on (of which i ]kept all ) oops.\n",
      "3    Shimmer, surprisingly goes with lots I ordered this in carbon for store pick up, and had a ton of stuff (as always) to try on and used this top to pair (skirts and pants). everything went with it. the color is really nice charcoal with shimmer, and went well with pencil skirts, flare pants, etc. my only compaint is it is a bit big, sleeves are long and it doesn't go in petite. also a bit loose for me, but no xxs... so i kept it and wil ldecide later since the light color is already sold out in hte smallest size...\n",
      "4                                                                                                                             Runs big Bought the black xs to go under the larkspur midi dress because they didn't bother lining the skirt portion (grrrrrrrrrrr).\\r\\r\\nmy stats are 34a-28/29-36 and the xs fit very smoothly around the chest and was flowy around my lower half, so i would say it's running big.\\r\\r\\nthe straps are very pretty and it could easily be nightwear too.\\r\\r\\ni'm 5'6\" and it came to just below my knees.\n",
      "Name: full_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data['title'] = train_data['title'].fillna('No title provided')\n",
    "train_data['review_text'] = train_data['review_text'].fillna('No review provided')\n",
    "\n",
    "test_data['title'] = test_data['title'].fillna('No title provided')\n",
    "test_data['review_text'] = test_data['review_text'].fillna('No review provided')\n",
    "\n",
    "\n",
    "train_data['title'] = train_data['title'].astype(str)\n",
    "train_data['review_text'] = train_data['review_text'].astype(str)\n",
    "test_data['title'] = test_data['title'].astype(str)\n",
    "test_data['review_text'] = test_data['review_text'].astype(str)\n",
    "\n",
    "\n",
    "train_data['full_text'] = train_data['title'] + \" \" + train_data['review_text']\n",
    "test_data['full_text'] = test_data['title'] + \" \" + test_data['review_text']\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(train_data['full_text'].head())\n",
    "print(test_data['full_text'].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                            no title provided absolutely wonderful silky and sexy and comfortable\n",
      "1        some major design flaws i had such high hopes for this dress and really wanted it to work for me i initially ordered the petite small my usual size but i found this to be outrageously small so small in fact that i could not zip it up exclamation i reordered it in petite medium which was just ok overall the top half was comfortable and fit nicely but the bottom half had a very tight under layer and several somewhat cheap net over layers imo a major design flaw was the net over layer sewn directly into the zipper it c\n",
      "2                                                                                                                                                                                                                                                                                                flattering shirt this shirt is very flattering to all due to the adjustable front tie it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan love this shirt exclamation exclamation exclamation \n",
      "3                             not for the very petite i love tracy reese dresses but this one is not for the very petite i am just under feet tall and usually wear a p in this brand this dress was very pretty out of the package but its a lot of dress the skirt is long and very full so it overwhelmed my small frame not a stranger to alterations shortening and narrowing the skirt would take away from the embellishment of the garment i love the color and the idea of the style but it just did not work on me i returned this dress\n",
      "4                                                                                                                                                                                                                                                                                                                                                                   flattering i love this dress i usually get an xs but it runs a little snug in bust so i ordered up a size very flattering and feminine with the usual retailer flair for style\n",
      "                                                                                                                                                                                                                                                                           ...                                                                                                                                                                                                                                                                    \n",
      "16436                                                                                                                                                                                                                                                                                                                                                                  great dress for many occasions i was very happy to snag this dress at such a great price exclamation its very easy to slip on and has a very flattering cut and color combo\n",
      "16437                                                                                                                                                                                                                                                                                               wish it was made of cotton it reminds me of maternity clothes soft stretchy shiny material cut is flattering and drapes nicely i only found one button to close front looked awkward nice long sleeves not for me but maybe for others just ok\n",
      "16438                                                                                                                                                                                                                                                                                                                cute but see through this fit well but the top was very see through this never would have worked for me im glad i was able to try it on in the store and didnt order it online with different fabric it would have been great\n",
      "16439                                                very cute dress perfect for summer parties and we i bought this dress for a wedding i have this summer and its so cute unfortunately the fit isnt perfect the medium fits my waist perfectly but was way too long and too big in the bust and shoulders if i wanted to spend the money i could get it tailored but i just felt like it might not be worth it side note this dress was delivered to me with a nordstrom tag on it and i found it much cheaper there after looking exclamation \n",
      "16440                                                                                                                                                                                                                                                                                                                                                               please make more like this one exclamation this dress in a lovely platinum is feminine and fits perfectly easy to wear and comfy too exclamation highly recommend exclamation \n",
      "Name: full_text, Length: 16441, dtype: object\n",
      "0                                                                                                                                                                                                                                                               no title provided love this dress exclamation its so pretty i happened to find it in a store and im glad i did bc i never would have ordered it online bc its petite i bought a petite and am i love the length on me hits just a little below the knee would definitely be a true midi on someone who is truly petite\n",
      "1                                                                                                                                                                                                                                                                                                                                                                                                                       my favorite buy exclamation i love this jumpsuit its fun flirty and fabulous exclamation every time i wear it i get nothing but great compliments exclamation \n",
      "2                                                                          cagrcoal shimmer fun i aded this in my basket at hte last mintue to see what it would look like in person store pick up i went with teh darkler color only because i am so pale hte color is really gorgeous and turns out it mathced everythiing i was trying on with it prefectly it is a little baggy on me and hte xs is hte msallet size bummer no petite i decided to jkeep it though because as i said it matvehd everything my ejans pants and the skirts i waas trying on of which i kept all oops\n",
      "3                                                                    shimmer surprisingly goes with lots i ordered this in carbon for store pick up and had a ton of stuff as always to try on and used this top to pair skirts and pants everything went with it the color is really nice charcoal with shimmer and went well with pencil skirts flare pants etc my only compaint is it is a bit big sleeves are long and it doesnt go in petite also a bit loose for me but no xxs so i kept it and wil ldecide later since the light color is already sold out in hte smallest size\n",
      "4                                                                                                                                                                                                                          runs big bought the black xs to go under the larkspur midi dress because they didnt bother lining the skirt portion gr my stats are a and the xs fit very smoothly around the chest and was flowy around my lower half so i would say its running big the straps are very pretty and it could easily be nightwear too im and it came to just below my knees\n",
      "                                                                                                                                                                                                                                                                                             ...                                                                                                                                                                                                                                                                                      \n",
      "7040                                                                                                                                                                                                   comfy pants these pants overall are very comfortable but have an unusual fit they tend to run a bit short and i always have to get pants hemmed shorter so if you have long legs or like more draping you probably wont like these they also ran a bit large in the waist and thigh a bit puffy i had to size down in order to get a good fit very good quality and cute design\n",
      "7041                                                                                           sweet stripes i love this little chemise exclamation the adjustable straps sold me because im petite i generally wear a smallp im about lbs i purchased a small and it fit perfect exclamation the fabric is nice not too thin or too thick i would totally wear it just as easily as a nightgown or beach coverup ive never been able to wear scrappy dresses but it could probably pass for one of those too its flattering and pretty without being too pretty if you get my meaning\n",
      "7042                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              no title provided no review provided\n",
      "7043    much better in person exclamation yes this is a great dress exclamation i wasnt sure about it online because of the color combination i think i would have preferred the gray color but it was sold out it received very good reviews online so i thought it was worth the risk at the sale price i am always on the hunt for great dresses at great prices who isnt question exclamation once i received it and tried it on oh wow exclamation i love it is so flattering it is a very pretty dress i think i will wear this all the time i am actually thinking of all the d\n",
      "7044                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              no title provided no review provided\n",
      "Name: full_text, Length: 7045, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def text_cleaning(text):\n",
    "    text = text.lower()  # convert text to lowercase\n",
    "    text = re.sub(r'<.*?>', '', text)  # remove HTML tags\n",
    "    text = re.sub(r'\\d+', '', text)  # remove numbers\n",
    "    text = re.sub(r'\\b(\\w+)( \\1\\b)+', r'\\1', text)  # remove repeated words\n",
    "    text = re.sub(r'([a-z])\\1{2,}', r'\\1', text)  # reduce elongated words to two letters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # remove punctuation\n",
    "    text = re.sub(r'\\r\\n|\\r|\\n', ' ', text)  # remove new lines and carriage returns\n",
    "    text = re.sub(r'\\s{2,}', ' ', text)  # replace multiple spaces with a single space\n",
    "\n",
    "    return text\n",
    "\n",
    "# Function to replace specific punctuation with tokens\n",
    "def punctuation(text):\n",
    "    text = text.replace('!', ' EXCLAMATION ')\n",
    "    text = text.replace('?', ' QUESTION ')\n",
    "    return re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "\n",
    "\n",
    "train_data['full_text'] = train_data['full_text'].apply(punctuation).apply(text_cleaning)\n",
    "test_data['full_text'] = test_data['full_text'].apply(punctuation).apply(text_cleaning)\n",
    "\n",
    "\n",
    "print(train_data['full_text'])\n",
    "print(test_data['full_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IaKZ2bvCeVCB"
   },
   "source": [
    "Feature engineering for this approach :  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         1.         0.         0.         0.\n",
      "  1.         0.         0.         0.         0.         0.\n",
      "  0.         0.         1.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.18518519\n",
      "  1.        ]\n",
      " [1.         0.         0.         0.         0.         1.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  1.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.51851852\n",
      "  0.        ]\n",
      " [1.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         1.         0.         1.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.35802469\n",
      "  1.        ]\n",
      " [1.         0.         0.         0.         0.         1.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  1.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.38271605\n",
      "  0.        ]\n",
      " [1.         0.         0.         0.         0.         1.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  1.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.07407407\n",
      "  1.        ]]\n",
      "[[1.         0.         0.         0.         0.         1.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  1.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.19753086\n",
      "  1.        ]\n",
      " [0.         1.         0.         0.         1.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         1.\n",
      "  0.         0.         0.         0.         0.         0.39506173\n",
      "  1.        ]\n",
      " [0.         1.         0.         0.         0.         0.\n",
      "  0.         0.         0.         1.         0.         0.\n",
      "  0.         0.         0.         0.         0.         1.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.25925926\n",
      "  1.        ]\n",
      " [0.         1.         0.         0.         0.         0.\n",
      "  0.         0.         0.         1.         0.         0.\n",
      "  0.         0.         0.         0.         0.         1.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.25925926\n",
      "  1.        ]\n",
      " [0.         0.         1.         0.         0.         0.\n",
      "  1.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         1.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.32098765\n",
      "  1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-908a54db5199>:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['class_name'].fillna('Missing', inplace=True)\n",
      "<ipython-input-10-908a54db5199>:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['division_name'].fillna('Missing', inplace=True)\n",
      "<ipython-input-10-908a54db5199>:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['department_name'].fillna('Missing', inplace=True)\n",
      "<ipython-input-10-908a54db5199>:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['class_name'].fillna('Missing', inplace=True)\n",
      "<ipython-input-10-908a54db5199>:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['division_name'].fillna('Missing', inplace=True)\n",
      "<ipython-input-10-908a54db5199>:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['department_name'].fillna('Missing', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "\n",
    "\n",
    "## Handling missing values and combine sparse categories\n",
    "def numerical_features(data):\n",
    "\n",
    "    data['class_name'].fillna('Missing', inplace=True)\n",
    "    data['division_name'].fillna('Missing', inplace=True)\n",
    "    data['department_name'].fillna('Missing', inplace=True)\n",
    "\n",
    "    #@# Combine sparse categories\n",
    "    threshold = 100\n",
    "    value_counts = data['class_name'].value_counts()\n",
    "    to_combine = value_counts[value_counts <= threshold].index\n",
    "    data['class_name'] = data['class_name'].apply(lambda x: 'Other' if x in to_combine else x)\n",
    "\n",
    "    return data\n",
    "\n",
    "train_data = numerical_features(train_data)\n",
    "test_data = numerical_features(test_data)\n",
    "\n",
    "### One hot encoding :\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_features = encoder.fit_transform(train_data[['division_name', 'department_name', 'class_name']])\n",
    "encoded_test_features = encoder.transform(test_data[['division_name', 'department_name', 'class_name']])\n",
    "\n",
    "# i will Normalize only age since recommended_ind is binary :\n",
    "scaler = MinMaxScaler()\n",
    "train_data['age'] = scaler.fit_transform(train_data[['age']])\n",
    "test_data['age'] = scaler.transform(test_data[['age']])\n",
    "\n",
    "non_text_features = np.hstack((encoded_features, train_data[['age', 'recommended_ind']].values))\n",
    "non_text_test_features = np.hstack((encoded_test_features, test_data[['age', 'recommended_ind']].values))\n",
    "\n",
    "print(non_text_features[:5])\n",
    "print(non_text_test_features[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16441, 31)\n",
      "(7045, 31)\n"
     ]
    }
   ],
   "source": [
    "print(non_text_features.shape)\n",
    "print(non_text_test_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adjusting the labels to go with what keras expects :\n",
    "y_train = train_data['rating'].values - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C97iGLp0g_kw"
   },
   "source": [
    "To solve the class imbalance , i tried previously to oversample the minority classes but i didn't get good results so for this approach i decided to use class weights instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "print(class_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cI8xj9uTftQB"
   },
   "source": [
    "The custom trained Word2Vec embeddings : ( i found an article where they tried many models with different embeddings and most of the times when they used Word2Vec the model performed better so this is form where i got the idea to try it . This is not pretrained but trained on my data )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (15733, 100)\n",
      "Max sequence length: 104\n",
      "Padded train shape: (16441, 104)\n",
      "Padded test shape: (7045, 104)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "# Tokenize text data\n",
    "train_tokens = [text.split() for text in train_data['full_text']]\n",
    "test_tokens = [text.split() for text in test_data['full_text']]\n",
    "\n",
    "# Train custom Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences=train_tokens, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Step 2: Create the embedding matrix\n",
    "vocab_size = len(word2vec_model.wv.index_to_key)  # Number of unique words in the Word2Vec model\n",
    "embedding_dim = word2vec_model.vector_size         # Embedding dimension\n",
    "embedding_matrix = np.zeros((vocab_size + 1, embedding_dim))\n",
    "\n",
    "word_index = {word: idx + 1 for idx, word in enumerate(word2vec_model.wv.index_to_key)}\n",
    "\n",
    "for word, idx in word_index.items():\n",
    "    embedding_matrix[idx] = word2vec_model.wv[word]\n",
    "\n",
    "print(\"Embedding matrix shape:\", embedding_matrix.shape)\n",
    "\n",
    "# Step 3: Convert tokenized sequences to word indices\n",
    "train_sequences = [[word_index[word] for word in tokens if word in word_index] for tokens in train_tokens]\n",
    "test_sequences = [[word_index[word] for word in tokens if word in word_index] for tokens in test_tokens]\n",
    "\n",
    "# Step 4: Determine max_seq_length and pad sequences\n",
    "review_lengths = [len(seq) for seq in train_sequences]\n",
    "max_seq_length = int(np.percentile(review_lengths, 95))  # 95th percentile of review lengths\n",
    "print(\"Max sequence length:\", max_seq_length)\n",
    "\n",
    "train_sequences_padded = pad_sequences(train_sequences, maxlen=max_seq_length, padding='post', truncating='post')\n",
    "test_sequences_padded = pad_sequences(test_sequences, maxlen=max_seq_length, padding='post', truncating='post')\n",
    "\n",
    "print(\"Padded train shape:\", train_sequences_padded.shape)\n",
    "print(\"Padded test shape:\", test_sequences_padded.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-Yf1PPagarN"
   },
   "source": [
    "CNN-BILSTM MODEL (THE BEST ONE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{4: 0.35772410791993037, 3: 0.9249507735583685, 2: 1.626211671612265, 1: 2.989272727272727, 0: 5.748601398601399}\n"
     ]
    }
   ],
   "source": [
    "class_weights2 = {\n",
    "    4: 0.35772410791993037,\n",
    "    3: 0.9249507735583685,\n",
    "    2: 1.626211671612265,\n",
    "    1: 2.989272727272727,\n",
    "    0: 5.748601398601399\n",
    "    }\n",
    "print(class_weights2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,573,300</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">102</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">38,528</span> │ embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling1d_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ input_layer_7             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ bidirectional_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ max_pooling1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)           │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">965</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m104\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m104\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │      \u001b[38;5;34m1,573,300\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m102\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │         \u001b[38;5;34m38,528\u001b[0m │ embedding_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling1d_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ input_layer_7             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ bidirectional_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m98,816\u001b[0m │ max_pooling1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)           │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m2,048\u001b[0m │ input_layer_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ bidirectional_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │            \u001b[38;5;34m965\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,713,657</span> (6.54 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,713,657\u001b[0m (6.54 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,713,657</span> (6.54 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,713,657\u001b[0m (6.54 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding, Input, Dense, Dropout, GRU, Bidirectional, Conv1D, MaxPooling1D, concatenate\n",
    "\n",
    "# Input layers\n",
    "input_text = Input(shape=(max_seq_length,))\n",
    "input_non_text = Input(shape=(non_text_features.shape[1],))\n",
    "\n",
    "# Embedding layer\n",
    "embedding_layer = Embedding(input_dim=vocab_size + 1,\n",
    "                            output_dim=embedding_dim,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_seq_length,\n",
    "                            trainable=True)(input_text)\n",
    "\n",
    "# CNN branch\n",
    "cnn_layer = Conv1D(filters=128, kernel_size=3, activation='relu')(embedding_layer)\n",
    "cnn_layer = MaxPooling1D(pool_size=2)(cnn_layer)\n",
    "\n",
    "# BiLSTM branch\n",
    "bilstm_layer = Bidirectional(LSTM(64))(cnn_layer)\n",
    "bilstm_layer = Dropout(0.3)(bilstm_layer)\n",
    "\n",
    "# Non-text branch\n",
    "non_text_layer = Dense(64, activation='relu')(input_non_text)\n",
    "non_text_layer = Dropout(0.3)(non_text_layer)\n",
    "\n",
    "# Concatenate branches\n",
    "concatenated = concatenate([bilstm_layer, non_text_layer])\n",
    "output = Dense(5, activation='softmax')(concatenated)\n",
    "\n",
    "# Compile the model\n",
    "modelr = Model(inputs=[input_text, input_non_text], outputs=output)\n",
    "modelr.compile(optimizer=Adam(learning_rate=0.0005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "modelr.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16441, 5)\n"
     ]
    }
   ],
   "source": [
    "## To go with our loss function :\n",
    "y_train = to_categorical(y_train)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16441, 104)\n",
      "(16441, 31)\n"
     ]
    }
   ],
   "source": [
    "print(train_sequences_padded.shape)\n",
    "print(non_text_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='cnn_bilstm_best_model.keras',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=6,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.3/615.3 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tensorboard, tensorflow\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.17.1\n",
      "    Uninstalling tensorboard-2.17.1:\n",
      "      Successfully uninstalled tensorboard-2.17.1\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.17.1\n",
      "    Uninstalling tensorflow-2.17.1:\n",
      "      Successfully uninstalled tensorflow-2.17.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.18.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed tensorboard-2.18.0 tensorflow-2.18.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "ace1512207f74ed38fd99f085816a6e2",
       "pip_warning": {
        "packages": [
         "tensorflow"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m408/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4135 - loss: 1.4880\n",
      "Epoch 1: val_loss improved from inf to 1.10281, saving model to cnn_bilstm_best_model.keras\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.4144 - loss: 1.4864 - val_accuracy: 0.5202 - val_loss: 1.1028\n",
      "Epoch 2/20\n",
      "\u001b[1m406/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6062 - loss: 1.0893\n",
      "Epoch 2: val_loss improved from 1.10281 to 0.87935, saving model to cnn_bilstm_best_model.keras\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.6063 - loss: 1.0889 - val_accuracy: 0.6245 - val_loss: 0.8794\n",
      "Epoch 3/20\n",
      "\u001b[1m408/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6373 - loss: 0.9762\n",
      "Epoch 3: val_loss did not improve from 0.87935\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.6373 - loss: 0.9763 - val_accuracy: 0.6002 - val_loss: 0.9111\n",
      "Epoch 4/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6632 - loss: 0.9164\n",
      "Epoch 4: val_loss improved from 0.87935 to 0.82270, saving model to cnn_bilstm_best_model.keras\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.6632 - loss: 0.9163 - val_accuracy: 0.6345 - val_loss: 0.8227\n",
      "Epoch 5/20\n",
      "\u001b[1m410/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6819 - loss: 0.8375\n",
      "Epoch 5: val_loss improved from 0.82270 to 0.78971, saving model to cnn_bilstm_best_model.keras\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.6819 - loss: 0.8375 - val_accuracy: 0.6580 - val_loss: 0.7897\n",
      "Epoch 6/20\n",
      "\u001b[1m406/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7102 - loss: 0.7724\n",
      "Epoch 6: val_loss did not improve from 0.78971\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.7101 - loss: 0.7726 - val_accuracy: 0.6245 - val_loss: 0.8552\n",
      "Epoch 7/20\n",
      "\u001b[1m409/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7316 - loss: 0.6913\n",
      "Epoch 7: val_loss did not improve from 0.78971\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.7315 - loss: 0.6914 - val_accuracy: 0.6510 - val_loss: 0.7971\n",
      "Epoch 8/20\n",
      "\u001b[1m409/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7520 - loss: 0.6031\n",
      "Epoch 8: val_loss did not improve from 0.78971\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.7519 - loss: 0.6033 - val_accuracy: 0.5725 - val_loss: 0.9666\n",
      "Epoch 9/20\n",
      "\u001b[1m410/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7616 - loss: 0.5656\n",
      "Epoch 9: val_loss did not improve from 0.78971\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.7616 - loss: 0.5657 - val_accuracy: 0.6634 - val_loss: 0.8253\n",
      "Epoch 10/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7924 - loss: 0.4729\n",
      "Epoch 10: val_loss did not improve from 0.78971\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.7924 - loss: 0.4729 - val_accuracy: 0.6370 - val_loss: 0.8752\n",
      "Epoch 11/20\n",
      "\u001b[1m409/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8137 - loss: 0.4110\n",
      "Epoch 11: val_loss did not improve from 0.78971\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.8136 - loss: 0.4111 - val_accuracy: 0.6452 - val_loss: 0.9035\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "history = modelr.fit([train_sequences_padded, non_text_features], y_train,\n",
    "                    validation_split=0.2,\n",
    "                    epochs=20,\n",
    "                    batch_size=32,\n",
    "                    class_weight=class_weights2,\n",
    "                    callbacks = [checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "# Loading the best saved model\n",
    "best_modell1 = load_model('cnn_bilstm_best_model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "test_predictions = modelr.predict([test_sequences_padded, non_text_test_features])\n",
    "predicted_ratings = test_predictions.argmax(axis=1) + 1  # Converting the probabilities back to ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created: submission.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_data['id'],\n",
    "    'rating': predicted_ratings\n",
    "})\n",
    "\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file created: submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RebARYdsvI9h"
   },
   "source": [
    "i tried many methods and models before and after my best model , these are some of them :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_5GPp3SoumSM"
   },
   "source": [
    "I tried to manually adjust the weights to maybe balance the training better , it gave good results with a CNN-RNN model i previously tried but not my best model CNN-BILSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 6.5, 1: 5.5, 2: 5.5, 3: 2.0, 4: 0.9}\n"
     ]
    }
   ],
   "source": [
    "class_weight3 = {\n",
    "    0: 6.5,\n",
    "    1: 5.5,\n",
    "    2: 5.5,\n",
    "    3: 2.0,\n",
    "    4: 0.9\n",
    "}\n",
    "print(class_weight3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-gLuV_UXygQ"
   },
   "source": [
    "After the good results of the CNN-BILSTM , i tried a CNN-BIGRU but it gave me less results than the previous one ( 0.499)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_15\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_15\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_36            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ embedding_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,575,500</span> │ input_layer_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">102</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">38,528</span> │ embedding_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ input_layer_37            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling1d_19          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ input_layer_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ bidirectional_16          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">74,496</span> │ max_pooling1d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)           │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_15            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ dropout_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">965</span> │ concatenate_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_36            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m104\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ embedding_18 (\u001b[38;5;33mEmbedding\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m104\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │      \u001b[38;5;34m1,575,500\u001b[0m │ input_layer_36[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_21 (\u001b[38;5;33mConv1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m102\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │         \u001b[38;5;34m38,528\u001b[0m │ embedding_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ input_layer_37            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling1d_19          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ conv1d_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m2,048\u001b[0m │ input_layer_37[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ bidirectional_16          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m74,496\u001b[0m │ max_pooling1d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)           │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_24 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ dense_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_15            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ bidirectional_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ dropout_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_31 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │            \u001b[38;5;34m965\u001b[0m │ concatenate_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,691,537</span> (6.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,691,537\u001b[0m (6.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,691,537</span> (6.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,691,537\u001b[0m (6.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from keras.layers import  GRU\n",
    "\n",
    "\n",
    "# Input layers\n",
    "input_text = Input(shape=(max_seq_length,))\n",
    "input_non_text = Input(shape=(non_text_features.shape[1],))\n",
    "\n",
    "# Embedding layer\n",
    "embedding_layer = Embedding(input_dim=vocab_size + 1,\n",
    "                            output_dim=embedding_dim,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_seq_length,\n",
    "                            trainable=True)(input_text)\n",
    "\n",
    "# CNN branch\n",
    "cnn_layer = Conv1D(filters=128, kernel_size=3, activation='relu')(embedding_layer)\n",
    "cnn_layer = MaxPooling1D(pool_size=2)(cnn_layer)\n",
    "\n",
    "# BiGRU branch\n",
    "bigru_layer = Bidirectional(GRU(64, return_sequences=False))(cnn_layer)\n",
    "\n",
    "\n",
    "# Non-text branch\n",
    "non_text_layer = Dense(64, activation='relu')(input_non_text)\n",
    "non_text_layer = Dropout(0.3)(non_text_layer)\n",
    "\n",
    "# Concatenate branches\n",
    "concatenated = concatenate([bigru_layer, non_text_layer])\n",
    "output = Dense(5, activation='softmax')(concatenated)\n",
    "\n",
    "# Compile\n",
    "model_gru = Model(inputs=[input_text, input_non_text], outputs=output)\n",
    "model_gru.compile(optimizer=Adam(learning_rate=0.0005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model_gru.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.3960 - loss: 1.4753\n",
      "Epoch 1: val_loss improved from inf to 0.99046, saving model to best_cnn_gru_model.keras\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 113ms/step - accuracy: 0.3962 - loss: 1.4750 - val_accuracy: 0.5844 - val_loss: 0.9905 - learning_rate: 5.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.5944 - loss: 1.1102\n",
      "Epoch 2: val_loss improved from 0.99046 to 0.90177, saving model to best_cnn_gru_model.keras\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 112ms/step - accuracy: 0.5945 - loss: 1.1101 - val_accuracy: 0.5923 - val_loss: 0.9018 - learning_rate: 5.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.6437 - loss: 0.9573\n",
      "Epoch 3: val_loss improved from 0.90177 to 0.81957, saving model to best_cnn_gru_model.keras\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 111ms/step - accuracy: 0.6437 - loss: 0.9573 - val_accuracy: 0.6339 - val_loss: 0.8196 - learning_rate: 5.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.6641 - loss: 0.8889\n",
      "Epoch 4: val_loss did not improve from 0.81957\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 112ms/step - accuracy: 0.6641 - loss: 0.8889 - val_accuracy: 0.6309 - val_loss: 0.8304 - learning_rate: 5.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.6944 - loss: 0.8402\n",
      "Epoch 5: val_loss did not improve from 0.81957\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 114ms/step - accuracy: 0.6944 - loss: 0.8402 - val_accuracy: 0.6169 - val_loss: 0.8418 - learning_rate: 5.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.7169 - loss: 0.7383\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.81957\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 112ms/step - accuracy: 0.7169 - loss: 0.7383 - val_accuracy: 0.6102 - val_loss: 0.8773 - learning_rate: 5.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.7395 - loss: 0.6555\n",
      "Epoch 7: val_loss did not improve from 0.81957\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 113ms/step - accuracy: 0.7396 - loss: 0.6554 - val_accuracy: 0.6318 - val_loss: 0.8396 - learning_rate: 2.5000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.7663 - loss: 0.5751\n",
      "Epoch 8: val_loss did not improve from 0.81957\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 114ms/step - accuracy: 0.7664 - loss: 0.5751 - val_accuracy: 0.6248 - val_loss: 0.8561 - learning_rate: 2.5000e-04\n",
      "Epoch 8: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model_gru.fit(\n",
    "    [train_sequences_padded, non_text_features],\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    class_weight=class_weights2,\n",
    "    callbacks=[early_stopping,checkpoint],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKUxkpJlzoFR"
   },
   "source": [
    "I tried enhancing the CNN-BILSTM model but it didn't give better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_18            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ embedding_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,575,500</span> │ input_layer_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">102</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">38,528</span> │ embedding_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling1d_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ max_pooling1d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │ batch_normalization_2… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ input_layer_19            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling1d_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ input_layer_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ bidirectional_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │ max_pooling1d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)           │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_3… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_6             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,605</span> │ concatenate_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_18            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m104\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ embedding_9 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m104\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │      \u001b[38;5;34m1,575,500\u001b[0m │ input_layer_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_11 (\u001b[38;5;33mConv1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m102\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │         \u001b[38;5;34m38,528\u001b[0m │ embedding_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling1d_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ conv1d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │            \u001b[38;5;34m512\u001b[0m │ max_pooling1d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_12 (\u001b[38;5;33mConv1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m16,448\u001b[0m │ batch_normalization_2… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ input_layer_19            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling1d_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ conv1d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m2,048\u001b[0m │ input_layer_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ bidirectional_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m197,632\u001b[0m │ max_pooling1d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)           │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │            \u001b[38;5;34m256\u001b[0m │ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ bidirectional_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_3… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_6             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m320\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │          \u001b[38;5;34m1,605\u001b[0m │ concatenate_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,832,529</span> (6.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,832,529\u001b[0m (6.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,832,145</span> (6.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,832,145\u001b[0m (6.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from keras.layers import  BatchNormalization\n",
    "\n",
    "\n",
    "# Input layers\n",
    "input_text = Input(shape=(max_seq_length,))\n",
    "input_non_text = Input(shape=(non_text_features.shape[1],))\n",
    "\n",
    "# Embedding layer\n",
    "embedding_layer = Embedding(input_dim=vocab_size + 1,\n",
    "                            output_dim=embedding_dim,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_seq_length,\n",
    "                            trainable=True)(input_text)\n",
    "\n",
    "# CNN branch with two Conv1D layers\n",
    "cnn_layer = Conv1D(filters=128, kernel_size=3, activation='relu')(embedding_layer)\n",
    "cnn_layer = MaxPooling1D(pool_size=2)(cnn_layer)\n",
    "cnn_layer = BatchNormalization()(cnn_layer)\n",
    "\n",
    "cnn_layer = Conv1D(filters=64, kernel_size=2, activation='relu')(cnn_layer)\n",
    "cnn_layer = MaxPooling1D(pool_size=2)(cnn_layer)\n",
    "\n",
    "# BiLSTM branch\n",
    "bilstm_layer = Bidirectional(LSTM(128))(cnn_layer)\n",
    "bilstm_layer = Dropout(0.3)(bilstm_layer)\n",
    "\n",
    "# Non-text branch\n",
    "non_text_layer = Dense(64, activation='relu')(input_non_text)\n",
    "non_text_layer = BatchNormalization()(non_text_layer)\n",
    "non_text_layer = Dropout(0.3)(non_text_layer)\n",
    "concatenated = concatenate([bilstm_layer, non_text_layer])\n",
    "output = Dense(5, activation='softmax')(concatenated)\n",
    "\n",
    "\n",
    "modelr = Model(inputs=[input_text, input_non_text], outputs=output)\n",
    "modelr.compile(optimizer=Adam(learning_rate=0.0007), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "modelr.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "255YNwGXzsn_"
   },
   "source": [
    "TRAINING THE  ENHANCED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.4049 - loss: 1.4670\n",
      "Epoch 1: val_loss improved from inf to 0.88427, saving model to best_cnn_enhanced_model.keras\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 128ms/step - accuracy: 0.4051 - loss: 1.4666 - val_accuracy: 0.6345 - val_loss: 0.8843 - learning_rate: 5.0000e-04\n",
      "Epoch 2/40\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.5979 - loss: 1.0702\n",
      "Epoch 2: val_loss did not improve from 0.88427\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 122ms/step - accuracy: 0.5979 - loss: 1.0702 - val_accuracy: 0.5421 - val_loss: 0.9865 - learning_rate: 5.0000e-04\n",
      "Epoch 3/40\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6355 - loss: 0.9398\n",
      "Epoch 3: val_loss improved from 0.88427 to 0.86390, saving model to best_cnn_enhanced_model.keras\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 121ms/step - accuracy: 0.6355 - loss: 0.9398 - val_accuracy: 0.6126 - val_loss: 0.8639 - learning_rate: 5.0000e-04\n",
      "Epoch 4/40\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.6671 - loss: 0.8529\n",
      "Epoch 4: val_loss improved from 0.86390 to 0.80838, saving model to best_cnn_enhanced_model.keras\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 124ms/step - accuracy: 0.6671 - loss: 0.8529 - val_accuracy: 0.6552 - val_loss: 0.8084 - learning_rate: 5.0000e-04\n",
      "Epoch 5/40\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6986 - loss: 0.7386\n",
      "Epoch 5: val_loss improved from 0.80838 to 0.79793, saving model to best_cnn_enhanced_model.keras\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 121ms/step - accuracy: 0.6986 - loss: 0.7386 - val_accuracy: 0.6595 - val_loss: 0.7979 - learning_rate: 5.0000e-04\n",
      "Epoch 6/40\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.7273 - loss: 0.6213\n",
      "Epoch 6: val_loss did not improve from 0.79793\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 125ms/step - accuracy: 0.7273 - loss: 0.6213 - val_accuracy: 0.6491 - val_loss: 0.8611 - learning_rate: 5.0000e-04\n",
      "Epoch 7/40\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.7572 - loss: 0.5329\n",
      "Epoch 7: val_loss did not improve from 0.79793\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 124ms/step - accuracy: 0.7572 - loss: 0.5329 - val_accuracy: 0.5160 - val_loss: 1.1575 - learning_rate: 5.0000e-04\n",
      "Epoch 8/40\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.7770 - loss: 0.4521\n",
      "Epoch 8: val_loss did not improve from 0.79793\n",
      "\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 131ms/step - accuracy: 0.7770 - loss: 0.4522 - val_accuracy: 0.6139 - val_loss: 0.9595 - learning_rate: 5.0000e-04\n",
      "Epoch 9/40\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.8235 - loss: 0.3388\n",
      "Epoch 9: val_loss did not improve from 0.79793\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 123ms/step - accuracy: 0.8234 - loss: 0.3388 - val_accuracy: 0.5616 - val_loss: 1.1781 - learning_rate: 2.5000e-04\n",
      "Epoch 10/40\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.8452 - loss: 0.2735\n",
      "Epoch 10: val_loss did not improve from 0.79793\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 127ms/step - accuracy: 0.8452 - loss: 0.2735 - val_accuracy: 0.6491 - val_loss: 1.0218 - learning_rate: 2.5000e-04\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "history = modelr.fit([train_sequences_padded, non_text_features], y_train,\n",
    "                     validation_split=0.2,\n",
    "                     epochs=40,\n",
    "                     batch_size=32,\n",
    "                     class_weight=class_weights2,\n",
    "                     callbacks=[checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3g9fv7Ety3S9"
   },
   "source": [
    "This is one is the first Bilstm model i tried with this preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">12,928</span> │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ input_layer_9             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ reshape_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,352</span> │ input_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ bidirectional_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ reshape_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)           │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_4             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,285</span> │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m12,928\u001b[0m │ input_layer_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ input_layer_9             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ reshape_4 (\u001b[38;5;33mReshape\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │          \u001b[38;5;34m4,352\u001b[0m │ input_layer_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ bidirectional_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m98,816\u001b[0m │ reshape_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)           │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_4             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ bidirectional_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │          \u001b[38;5;34m1,285\u001b[0m │ concatenate_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">117,381</span> (458.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m117,381\u001b[0m (458.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">117,381</span> (458.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m117,381\u001b[0m (458.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, concatenate, Bidirectional, LSTM\n",
    "from keras.layers import Reshape\n",
    "\n",
    "# Input layers\n",
    "input_text = Input(shape=(100,))\n",
    "input_non_text = Input(shape=(non_text_features.shape[1],))\n",
    "\n",
    "# Text branch\n",
    "text_layer = Dense(128, activation='relu')(input_text)\n",
    "text_layer = Reshape((1, 128))(text_layer)\n",
    "text_bi_lstm = Bidirectional(LSTM(64))(text_layer)\n",
    "\n",
    "\n",
    "\n",
    "# Non-text branch\n",
    "non_text_layer = Dense(64, activation='relu')(input_non_text)\n",
    "non_text_layer = Dropout(0.3)(non_text_layer)\n",
    "# Concatenate branches\n",
    "concatenated = concatenate([text_bi_lstm, non_text_layer])\n",
    "output = Dense(5, activation='softmax')(concatenated)\n",
    "\n",
    "# Compile\n",
    "model = Model(inputs=[input_text, input_non_text], outputs=output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.4642 - loss: 2.8951 - val_accuracy: 0.5534 - val_loss: 0.9826\n",
      "Epoch 2/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6065 - loss: 2.2584 - val_accuracy: 0.5424 - val_loss: 0.9984\n",
      "Epoch 3/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6195 - loss: 2.2124 - val_accuracy: 0.6181 - val_loss: 0.8790\n",
      "Epoch 4/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6158 - loss: 2.1771 - val_accuracy: 0.5999 - val_loss: 0.8776\n",
      "Epoch 5/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.6271 - loss: 2.1583 - val_accuracy: 0.5798 - val_loss: 0.9257\n",
      "Epoch 6/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6248 - loss: 2.1492 - val_accuracy: 0.6269 - val_loss: 0.8429\n",
      "Epoch 7/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6304 - loss: 2.1393 - val_accuracy: 0.6202 - val_loss: 0.8439\n",
      "Epoch 8/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6369 - loss: 2.0944 - val_accuracy: 0.5883 - val_loss: 0.9116\n",
      "Epoch 9/20\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6365 - loss: 2.1227 - val_accuracy: 0.6066 - val_loss: 0.8814\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7a155e1a67a0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit([train_sequences_padded, non_text_features], y_train,\n",
    "          validation_split = 0.2,\n",
    "          epochs=20,\n",
    "          batch_size=32\n",
    "          , class_weight=class_weights2,\n",
    "          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FXkc_0fTYNRa"
   },
   "source": [
    "Previously i tried using GloVe embeddings and these are the steps i used but since they were pre trained i tried to find alternative to them . ( hence why i tried to train Word2Vec )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 15755\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_data['full_text'])\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because index 0 is reserved\n",
    "\n",
    "\n",
    "print(\"Vocabulary size:\", vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_sequences = tokenizer.texts_to_sequences(train_data['full_text'])\n",
    "test_text_sequences = tokenizer.texts_to_sequences(test_data['full_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Sequence Length: 118\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Computing the maximum sequence length from the training data:\n",
    "\n",
    "sequence_lengths = [len(seq) for seq in train_text_sequences]\n",
    "max_seq_length = max(sequence_lengths)\n",
    "print(f\"Maximum Sequence Length: {max_seq_length}\")\n",
    "\n",
    "## let's plot the sequences length :\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(sequence_lengths, bins=50)\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Sequence Lengths')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample train padded: [[  36   59   49  241  497  835    3  570    3   65    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0]\n",
      " [ 157 1689  135 1002    2   71  298  194 1051   12    7   17    3   54\n",
      "   182    5    8  101   12   32    2 1171   60    1   98   47   18  234\n",
      "    23   10    2  229    7    8   31 5751   47   15   47    9  654   21\n",
      "     2  120   20  753    5   48    2 1754    5    9   98  106   85   16\n",
      "    39  559  251    1   24  665   16   65    3   26  265   10    1  185\n",
      "   665   71    4   22  151  278  476    3  533  687  466 4858  164  978\n",
      "  1755    4 1689  135 1427   16    1 4858  164  476  796 3576  308    1\n",
      "   432    5  387    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0]]\n",
      "Sample test padded: [[  36   59   49   19    7   17   30   15   87    2 1370    8  215    5\n",
      "     9    4  116    3   38  320    2  137  874    2  427   44   25   60\n",
      "     5  138  874   30   98    2   75    4   98    3   40    2   19    1\n",
      "    90   11   32  417   39    4   58  448    1  418   44  165   31    4\n",
      "   136 1262   11  434  450    6  724   98    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0]\n",
      " [  18  279  218    2   19   19   19    7  562   30  207  994    3  627\n",
      "   297  186    2   34    5    2  121  530   10   27  204    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# Pad sequences\n",
    "\n",
    "train_text = pad_sequences(train_text_sequences, maxlen=max_seq_length, padding='post')\n",
    "test_text= pad_sequences(test_text_sequences, maxlen=max_seq_length, padding='post')\n",
    "\n",
    "print(f\"Sample train padded: {train_text[:2]}\")\n",
    "print(f\"Sample test padded: {test_text[:2]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "glove_path = '/content/drive/My Drive/glove.6B.100d.txt'\n",
    "\n",
    "# Loading GloVe embeddings\n",
    "embeddings_index = {}\n",
    "with open(glove_path, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(f'Found {len(embeddings_index)} word vectors.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "# Preparing embedding matrix\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
